<!DOCTYPE html>
<html lang="en">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    
    <script>
        
        if (localStorage.getItem('darkMode') !== 'false') {
            document.documentElement.classList.add('dark');
        }
    </script>
    
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />


<title>
  
    Policing the Future: When Algorithms Carry a Badge and Bias | Bram Steensma
  
</title>


<meta name="description" content="Explore the ethical downfall of predictive policing as we examine why cities like Los Angeles are abandoning these controversial AI systems. This post delves into the critical concepts of algorithmic fairness, explainability, and governance, revealing how data-driven law enforcement often automates bias and erodes public trust, ultimately failing its most important ethical tests." />
<meta name="author" content="Bram Steensma" />
<link rel="canonical" href="http://localhost:1313/blog/policing-the-future/" />


<meta property="og:type" content="website" />
<meta property="og:title" content="Policing the Future: When Algorithms Carry a Badge and Bias | Bram Steensma" />
<meta property="og:description" content="Explore the ethical downfall of predictive policing as we examine why cities like Los Angeles are abandoning these controversial AI systems. This post delves into the critical concepts of algorithmic fairness, explainability, and governance, revealing how data-driven law enforcement often automates bias and erodes public trust, ultimately failing its most important ethical tests." />
<meta property="og:url" content="http://localhost:1313/blog/policing-the-future/" />
<meta property="og:image" content="http://localhost:1313/images/notme.png">
<meta property="og:image:width" content="1200" />
<meta property="og:image:height" content="630" />
<meta property="og:site_name" content="Bram Steensma" />


<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:title" content="Policing the Future: When Algorithms Carry a Badge and Bias | Bram Steensma" />
<meta name="twitter:description" content="Explore the ethical downfall of predictive policing as we examine why cities like Los Angeles are abandoning these controversial AI systems. This post delves into the critical concepts of algorithmic fairness, explainability, and governance, revealing how data-driven law enforcement often automates bias and erodes public trust, ultimately failing its most important ethical tests." />
<meta name="twitter:image" content="http://localhost:1313/images/notme.png" />


<link rel="icon" href="/favicon.ico" />


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/devicons/devicon@latest/devicon.min.css" />



    
    
    <style>
 
:root {
   
  
  
  --color-primary: #0F172A;
  --color-second: #8B5CF6;
  --color-third: #06B6D4;
  
  
   
  --color-primary-light: color-mix(in srgb, var(--color-primary) 80%, white);
  --color-primary-dark: color-mix(in srgb, var(--color-primary) 80%, black);
  --color-primary-lighter: color-mix(in srgb, var(--color-primary) 20%, white);
  
  --color-second-light: color-mix(in srgb, var(--color-second) 80%, white);
  --color-second-dark: color-mix(in srgb, var(--color-second) 80%, black);
  --color-second-lighter: color-mix(in srgb, var(--color-second) 20%, white);
  
  --color-third-light: color-mix(in srgb, var(--color-third) 80%, white);
  --color-third-dark: color-mix(in srgb, var(--color-third) 80%, black);
  --color-third-lighter: color-mix(in srgb, var(--color-third) 20%, white);
  
   
  --color-gray-50: color-mix(in srgb, var(--color-primary) 5%, white);
  --color-gray-100: color-mix(in srgb, var(--color-primary) 10%, white);
  --color-gray-300: color-mix(in srgb, var(--color-primary) 20%, white);
  --color-gray-400: color-mix(in srgb, var(--color-primary) 30%, white);
  --color-gray-500: color-mix(in srgb, var(--color-primary) 40%, white);
  --color-gray-600: color-mix(in srgb, var(--color-primary) 50%, black);
  --color-gray-700: color-mix(in srgb, var(--color-primary) 60%, black);
  --color-gray-800: color-mix(in srgb, var(--color-primary) 80%, black);
  --color-gray-900: color-mix(in srgb, var(--color-primary) 90%, black);
  
   
  --color-white: #ffffff;
  --color-black: #000000;
  
   
  --color-shadow-light: rgba(0, 0, 0, 0.1);
  --color-shadow-lighter: rgba(0, 0, 0, 0.05);
  --color-shadow-dark: rgba(0, 0, 0, 0.3);
  
   
  --color-text-muted: var(--color-gray-500);
  --color-border-secondary: var(--color-gray-300);
  --color-success: var(--color-second);
  
   
  --color-bg: var(--color-white);
  --color-bg-secondary: var(--color-gray-100);
  --color-text-primary: var(--color-gray-900);
  --color-text-secondary: var(--color-gray-700);
  --color-border: var(--color-gray-300);
}

 
.dark {
  --color-bg: color-mix(in srgb, var(--color-primary) 50%, black);
  --color-bg-secondary: color-mix(in srgb, var(--color-primary) 30%, black);
  --color-bg-tertiary: color-mix(in srgb, var(--color-primary) 40%, black);
  --color-text-primary: var(--color-gray-50);
  --color-text-secondary: var(--color-gray-300);
  --color-border: var(--color-gray-700);
  --color-text-muted: var(--color-gray-400);
  --color-border-secondary: var(--color-gray-600);
}
</style>

    
    
    
    <link rel="stylesheet" type='text/css' href="https://cdn.jsdelivr.net/gh/devicons/devicon@latest/devicon.min.css" />    
    <link rel="stylesheet" href="/css/main.css?v=1772202920" data-version="1772202920">
    <style>
         
        body {
            visibility: hidden;
        }
        .dark body {
            visibility: hidden;
        }
    </style>
</head>
<body class="bg-bg dark:bg-bg text-text-primary dark:text-text-primary flex flex-col min-h-screen transition-colors duration-200">

    <nav class="fixed w-full bg-bg dark:bg-bg shadow-md z-50" role="banner">
  <div class="max-w-7xl mx-auto px-3 sm:px-4 lg:px-6">
    <div class="flex justify-between h-16">
      <div class="flex items-center">
        <a href="/" class="text-3xl font-bold text-text-primary dark:text-text-primary font-heading">Bram Steensma</a>
      </div>
      <div class="hidden lg:flex items-center space-x-6">
        
          
                      
            
            <a href="/#about" class="nav-link text-text-primary dark:text-text-primary">About</a>
          
          
        
          
                      
            
            <a href="/#skills" class="nav-link text-text-primary dark:text-text-primary">Skills</a>
          
          
        
          
                      
            
            <a href="/#experience" class="nav-link text-text-primary dark:text-text-primary">Experience</a>
          
          
        
          
                      
            
            <a href="/projects/" class="nav-link text-text-primary dark:text-text-primary">Projects</a>
          
          
        
          
                      
            
            <a href="/blog/" class="nav-link text-text-primary dark:text-text-primary">Blog</a>
          
          
        
          
                      
            
            <a href="/#contact" class="nav-link text-text-primary dark:text-text-primary">Contact</a>
          
          
        

        
        <div class="flex items-center space-x-4" data-animation="social">
          
          <a href="https://www.linkedin.com/in/steensmab" target="_blank" rel="noopener noreferrer" class="text-text-primary dark:text-text-primary transition-transform duration-300 hover:scale-125">
            <i class="fab fa-linkedin-in text-xl"></i>
          </a>
          
          
          <a href="https://github.com/BramSteensma" target="_blank" rel="noopener noreferrer" class="text-text-primary dark:text-text-primary transition-transform duration-300 hover:scale-125">
            <i class="fab fa-github text-xl"></i>
          </a>
          
          
          
        </div>
        
        <button id="darkModeToggle" class="text-text-primary dark:text-text-primary focus:outline-none">
          <i class="fas fa-toggle-on dark:hidden"></i>
          <i class="fas fa-toggle-off hidden dark:block"></i>
        </button>
      </div>
      <div class="lg:hidden flex items-center space-x-4">
        
        <button id="darkModeToggleMobile" class="text-text-primary dark:text-text-primary focus:outline-none">
          <i class="fas fa-toggle-on dark:hidden"></i>
          <i class="fas fa-toggle-off hidden dark:block"></i>
        </button>
        <button id="menu-btn" class="text-text-primary dark:text-text-primary">
          <i class="fas fa-bars text-2xl"></i>
        </button>
      </div>
    </div>
  </div>

  
  <div id="mobile-menu" class="hidden lg:hidden bg-bg dark:bg-bg shadow-lg">
    <div class="px-2 pt-2 pb-3 space-y-1 sm:px-3">
      
        
          
          <a href="/#about" class="nav-link block px-3 py-2 rounded-md text-base font-medium text-text-primary dark:text-text-primary">
            About
          </a>
        
        
      
        
          
          <a href="/#skills" class="nav-link block px-3 py-2 rounded-md text-base font-medium text-text-primary dark:text-text-primary">
            Skills
          </a>
        
        
      
        
          
          <a href="/#experience" class="nav-link block px-3 py-2 rounded-md text-base font-medium text-text-primary dark:text-text-primary">
            Experience
          </a>
        
        
      
        
          
          <a href="/projects/" class="nav-link block px-3 py-2 rounded-md text-base font-medium text-text-primary dark:text-text-primary">
            Projects
          </a>
        
        
      
        
          
          <a href="/blog/" class="nav-link block px-3 py-2 rounded-md text-base font-medium text-text-primary dark:text-text-primary">
            Blog
          </a>
        
        
      
        
          
          <a href="/#contact" class="nav-link block px-3 py-2 rounded-md text-base font-medium text-text-primary dark:text-text-primary">
            Contact
          </a>
        
        
      
      
      
      <div class="flex items-center space-x-6 px-3 py-3 border-t border-border-primary dark:border-border-primary mt-2" data-animation="social">
        
        <a href="https://www.linkedin.com/in/steensmab" target="_blank" rel="noopener noreferrer" class="text-text-primary dark:text-text-primary transition-transform duration-300 hover:scale-125">
          <i class="fab fa-linkedin-in text-2xl"></i>
        </a>
        
        
        <a href="https://github.com/BramSteensma" target="_blank" rel="noopener noreferrer" class="text-text-primary dark:text-text-primary transition-transform duration-300 hover:scale-125">
          <i class="fab fa-github text-2xl"></i>
        </a>
        
        
        
      </div>
    </div>
  </div>

  
  <style>
    .group.open .submenu {
      opacity: 1 !important;
      visibility: visible !important;
    }
  </style>

  
  <script>
    
    document.addEventListener('DOMContentLoaded', function() {
      console.log('Navigation script loaded');
      
      const sectionLinks = document.querySelectorAll('.section-link');
      console.log('Found section links:', sectionLinks.length);
      const homePath = '\/';
      
      sectionLinks.forEach(link => {
        link.addEventListener('click', function(e) {
          e.preventDefault();
          console.log('Section link clicked:', this.getAttribute('data-section'));
          
          const section = this.getAttribute('data-section');
          const isHomePage = window.location.pathname === homePath || window.location.pathname === homePath + 'index.html' || window.location.pathname === homePath.replace(/\/$/, '');
          console.log('Is home page:', isHomePage);
          
          if (isHomePage) {
            
            const targetElement = document.querySelector(section);
            console.log('Target element found:', !!targetElement);
            if (targetElement) {
              targetElement.scrollIntoView({
                behavior: 'instant',
                block: 'start'
              });
            }
          } else {
            
            console.log('Navigating to:', homePath + section);
            window.location.href = homePath + section;
          }
        });
      });
      
      
      function handleHashScroll() {
        console.log('Checking for hash:', window.location.hash);
        if (window.location.hash) {
          const targetElement = document.querySelector(window.location.hash);
          console.log('Hash target element found:', !!targetElement);
          if (targetElement) {
            
            setTimeout(() => {
              console.log('Scrolling to hash target');
              targetElement.scrollIntoView({
                behavior: 'instant',
                block: 'start'
              });
            }, 100);
          }
        }
      }
      
      
      handleHashScroll();
      
      
      setTimeout(handleHashScroll, 500);
      setTimeout(handleHashScroll, 1000);
      
      
      window.addEventListener('hashchange', function() {
        console.log('Hash changed to:', window.location.hash);
        handleHashScroll();
      });
      
      
      window.addEventListener('load', function() {
        console.log('Window loaded, checking hash');
        setTimeout(handleHashScroll, 200);
      });
    });
    
    
    document.querySelectorAll('.group > a.nav-link, .group > button.nav-link').forEach(link => {
      link.addEventListener('click', function(e) {
        e.preventDefault();
        const group = this.closest('.group');
        const isOpen = group.classList.contains('open');

        
        document.querySelectorAll('.group').forEach(g => g.classList.remove('open'));

        
        if (!isOpen) {
          group.classList.add('open');
        }
      });

      document.addEventListener('click', function(event) {
        const group = link.closest('.group');
        if (!group.contains(event.target)) {
          group.classList.remove('open');
        }
      });
    });

    
    function toggleDarkMode() {
      const isDark = document.documentElement.classList.toggle('dark');
      localStorage.setItem('darkMode', isDark);
    }

    document.getElementById('darkModeToggle').addEventListener('click', toggleDarkMode);
    document.getElementById('darkModeToggleMobile').addEventListener('click', toggleDarkMode);

    
    document.querySelectorAll('#mobile-menu a').forEach(link => {
      link.addEventListener('click', function(e) {
        document.getElementById('mobile-menu').classList.add('hidden');
      });
    });


  </script>
</nav>




    <div class="w-full h-16"></div>

    <main class="flex-grow">
        
<section class="pt-8 pb-12 bg-bg dark:bg-bg">
  <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
    <div class="flex flex-col lg:flex-row gap-8">
      
      <div class="lg:w-2/3">
        <h1 class="text-3xl font-bold text-center mb-12 font-heading text-text-primary dark:text-text-primary">Policing the Future: When Algorithms Carry a Badge and Bias</h1>
        
        <div class="text-center text-text-secondary dark:text-text-secondary mb-8">
          <time datetime="2026-02-27">February 27, 2026</time>
        </div>
        
        <div class="prose max-w-none prose-lg markdown-content dark:prose-invert prose-gray [&_iframe]:min-h-[600px] [&_iframe]:w-full [&_img+em]:block [&_img+em]:text-center [&_img+em]:font-bold">
          <p>Artificial intelligence in law enforcement was sold with a powerful promise: the ability to stop crime before it happens. This proactive approach, shifting from reaction to prediction, presented an alluring vision of safer streets and optimized police resources. For years, tech companies championed predictive policing systems as the key to smarter, data-driven public safety.</p>
<p>However, as cities across the globe have discovered, the line between science fiction and reality is fraught with ethical peril. The deployment of these algorithms has become a crucial case study in the challenges of AI ethics. When we examine these systems through the lens of ethical AI frameworks, particularly the concepts outlined by Luciano Floridi, we see a fundamental conflict between computational logic and human justice. The real-world retreat from these technologies, most notably in cities like Los Angeles, signals a critical re-evaluation of what it means to police fairly in the digital age.</p>
<h2 id="a-real-world-case-study-the-lapd-and-predpol">A Real-World Case Study: The LAPD and PredPol</h2>
<p>Predictive policing systems primarily fall into two categories: place-based models and person-based models. Place-based models, like the one developed by PredPol (now Geolitica), use historical crime dataâ€”type, location, and timeâ€”to forecast where and when future crimes are most likely to occur, generating &ldquo;hotspot&rdquo; maps to direct patrols. Person-based systems, such as the LAPDâ€™s &ldquo;chronic offender&rdquo; program, attempt to predict which individuals are at the highest risk of being involved in future violent crimeâ€”either as perpetrators or victimsâ€”often by analyzing past arrest records, known associations, and other personal risk factors.</p>
<p>The Los Angeles Police Department (LAPD) was an early and prominent adopter of this technology. However, after years of use, the city decided to end its contracts. In 2019, the LAPD stopped using PredPolâ€™s hotspot software, and in 2020, it discontinued its own in-house &ldquo;chronic offender&rdquo; program. The reason for this reversal wasn&rsquo;t a failure of technology, but a failure of ethics. An audit by the cityâ€™s inspector general found it impossible to determine whether these programs actually helped reduce crime, and civil rights groups raised significant concerns about their discriminatory impact.
This high-profile withdrawal highlights the core ethical weaknesses that plague predictive policing systems nationwide.</p>
<h2 id="the-algorithms-original-sin-fairness-and-biased-data">The Algorithm&rsquo;s Original Sin: Fairness and Biased Data</h2>
<p>The most significant ethical failing of predictive policing is its inability to achieve fairness. In the context of AI, fairness means that a system does not produce discriminatory outcomes or reinforce existing inequalities. The problem for predictive policing algorithms is the data they are trained on.</p>
<p>These systems are fed historical crime data from police departments. This data is not a pure, objective record of all criminal activity. Instead, it is a record of reported crimes and enforced laws. For decades, policing in many American cities has disproportionately targeted low-income and minority communities. This results in more arrests for minor offenses, like loitering or drug possession, in these areas compared to more affluent, predominantly white neighborhoods where the same activities may occur but go unpoliced.
When this skewed data is fed into an algorithm, it creates a dangerous feedback loop:</p>
<ul>
<li>The AI analyzes historical arrest data and flags a minority neighborhood as a &ldquo;hotspot.&rdquo;</li>
<li>Police commanders dispatch more officers to patrol that specific area.</li>
<li>The increased police presence naturally leads to more citations and arrests for minor offenses.</li>
<li>This new arrest data is then fed back into the system, further solidifying the neighborhoodâ€™s status as a high-crime zone.</li>
</ul>
<p>The algorithm isn&rsquo;t predicting crime; it&rsquo;s predicting policing. It provides a veneer of mathematical objectivity to historical human bias, effectively automating and amplifying discrimination. This is precisely what critics in Los Angeles arguedâ€”that the software was sending officers back to the same communities over and over, leading to over-policing and eroding public trust.</p>
<h2 id="the-black-box-dilemma-and-the-need-for-explainability">The Black Box Dilemma and the Need for Explainability</h2>
<p>A core tenet of ethical AI is explainability, or the ability for humans to understand how an AI system arrived at its decision. If a community is subjected to heightened surveillance because an algorithm flagged their street corner, its residents deserve to know why.</p>
<p>Many predictive policing algorithms are proprietary &ldquo;black boxes.&rdquo; The companies that create them protect their code as a trade secret, making it impossible for outside auditors, civil rights organizations, or even the police departments themselves to fully vet the system. We don&rsquo;t know what variables the model is weighing or whether it&rsquo;s using proxies for protected characteristics like race or socioeconomic status. For example, could a variable like &ldquo;proximity to a check-cashing store&rdquo; act as a proxy for a low-income neighborhood? Without transparency, we can&rsquo;t know.</p>
<p>This lack of explainability makes it nearly impossible to challenge the systemâ€™s output, creating an environment where accountability is diffused and justice becomes opaque.</p>
<h2 id="whos-to-blame-the-crisis-of-algorithmic-accountability">Whoâ€™s to Blame? The Crisis of Algorithmic Accountability</h2>
<p>As philosopher Luciano Floridi points out, AI systems possess a form of intelligence without moral agency. They can identify complex patterns but cannot comprehend the real-world consequences of their recommendations. This creates a vacuum of algorithmic accountability.</p>
<p>When a predictive model repeatedly directs patrols to a community, leading to the harassment of innocent residents, who is responsible?</p>
<ul>
<li>Is it the police officer following the computerâ€™s recommendation?</li>
<li>Is it the police chief who signed the contract for the software?</li>
<li>Is it the data scientists who developed the algorithm?</li>
<li>Is it the software company that sold the product?</li>
</ul>
<p>Our legal system is built around human intent, but an algorithm has no intent. It simply optimizes for a given metric, like identifying areas with the highest probability of recorded crime. This diffusion of responsibility makes it incredibly difficult for affected individuals to seek recourse. A truly ethical AI framework insists that a human must always remain in the loop and bear ultimate responsibility for the system&rsquo;s impact.</p>
<h2 id="moving-beyond-the-law-the-role-of-soft-ethics">Moving Beyond the Law: The Role of Soft Ethics</h2>
<p>The conversation around predictive policing often gets stuck on what is legal. It is legal to use public arrest data to train an algorithm. But this is where soft ethics becomes essential. Soft ethics moves beyond legal compliance to ask what we should do. It is the domain of moral and social responsibility.</p>
<p>Soft ethics compels us to question the fundamental premise of the technology. Even if an algorithm could be perfected to be unbiased, is it right to place entire communities under a cloud of digital suspicion? Does the potential efficiency gain justify the erosion of trust between police and the people they serve?</p>
<p>This is the conversation that unfolded in places like Santa Cruz, Californiaâ€”the birthplace of PredPolâ€”which banned predictive policing in 2020. Community leaders decided that the social cost of algorithmic surveillance outweighed any purported benefits. Soft ethics encourages us to consider alternative solutions. Instead of sending more patrol cars to a &ldquo;hotspot,&rdquo; perhaps the data should prompt investment in community resources, like job training programs, mental health services, or better street lighting.</p>
<h2 id="the-path-forward-ai-governance-as-a-public-trust">The Path Forward: AI Governance as a Public Trust</h2>
<p>To prevent these ethical failures, we need robust AI governance. This means establishing clear policies, oversight bodies, and accountability structures to manage the entire lifecycle of an AI system, from procurement to deployment and retirement.</p>
<p>For technologies like predictive policing, effective governance would include:</p>
<ul>
<li>Mandatory Bias Audits: Independent, third-party audits to test for discriminatory outcomes before a system is purchased.</li>
<li>Public Transparency: Community impact assessments and public comment periods before any surveillance technology is deployed.</li>
<li>Clear Termination Criteria: Predetermined conditions under which a system will be decommissioned if it proves ineffective or harmful.</li>
<li>Human Oversight: Ensuring that algorithmic recommendations are treated as one data point among many, not as an unquestionable command.</li>
</ul>
<p>Governance is the mechanism by which we embed our societal values into our technological systems. Without it, we risk building an &ldquo;infosphere,&rdquo; as Floridi calls it, polluted by biased data and unaccountable power.</p>
<h2 id="conclusion">Conclusion</h2>
<p>The retreat from predictive policing in major cities like Los Angeles is not a rejection of technology itself. It is a recognition that AI is not a neutral tool. It is a socio-technical system that absorbs and reflects the values of the society that creates it. The promise of an efficient, crime-free future is deeply appealing, but it cannot come at the cost of justice and equality.</p>
<p>By applying ethical concepts like fairness, explainability, accountability, and soft ethics, we can see that these systems failed not on a technical level, but on a human one. They automated the past instead of building a better future. As we continue to integrate AI into the core functions of our society, the lessons from the algorithmic beat cop are clear: the ultimate goal cannot be mere efficiency. It must be justice. And justice is a metric that no algorithm can compute on its own.</p>

        </div>
      </div>

      
      
      <div class="lg:w-1/3">
        <div class="sticky top-24 max-h-[calc(100vh-8rem)] flex flex-col">
          <h2 class="text-xl font-bold mb-4 text-text-primary dark:text-text-primary flex-shrink-0">Related Content</h2>
          <div class="space-y-3 pr-2 overflow-y-auto flex-1 sidebar-scroll">
            
            
            <a href="/blog/when-anonymous-isnt-really-anonymous/" class="block group">
              <article class="bg-bg-secondary dark:bg-bg-tertiary rounded-md p-3 shadow-sm border border-border-primary dark:border-border-primary hover:shadow-md transition-shadow duration-200">
                
                <div class="flex gap-3 mb-2">
                  
                  <div class="w-16 flex-shrink-0">
                    
                    <div class="relative overflow-hidden">
                      <img 
                        src="/images/anonymous.jpg" 
                        alt="When Anonymous Isn&#39;t Really Anonymous: A Data Ethics Crisis" 
                        class="w-full h-16 object-contain bg-transparent transition-transform duration-300 group-hover:scale-105"
                        loading="lazy"
                      >
                      <div class="absolute inset-0 bg-gradient-to-t from-text-primary/20 to-transparent opacity-0 group-hover:opacity-100 transition-opacity duration-300"></div>
                    </div>
                    
                  </div>
                  
                  
                  <div class="flex-1 min-w-0">
                    <h3 class="text-sm font-semibold mb-1 text-text-primary dark:text-text-primary group-hover:text-primary dark:group-hover:text-primary-light transition-colors duration-300">
                      When Anonymous Isn&#39;t Really Anonymous: A Data Ethics Crisis
                    </h3>
                    
                    
                    <p class="text-xs text-text-secondary dark:text-text-secondary leading-relaxed line-clamp-2">This blog critically analyzes the ethical pitfalls of course evaluation surveys that promise anonymity but fail to deliver due to flawed system design</p>
                    
                  </div>
                </div>
                
                
                
                <div class="flex flex-wrap gap-1">
                  
                  <span class="bg-bg dark:bg-bg-secondary text-text-primary dark:text-text-primary px-1.5 py-0.5 rounded text-xs border border-border-primary dark:border-border-primary">
                    Data Analysis
                  </span>
                  
                  <span class="bg-bg dark:bg-bg-secondary text-text-primary dark:text-text-primary px-1.5 py-0.5 rounded text-xs border border-border-primary dark:border-border-primary">
                    Ethics
                  </span>
                  
                </div>
                
              </article>
            </a>
            
          </div>
        </div>
      </div>
      
    </div>
  </div>
</section>

    </main>

    <footer class="bg-bg-secondary dark:bg-bg-secondary text-text-primary py-12 border-t border-border-primary">
  <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
    <div class="flex flex-col md:flex-row justify-between items-center">
      <div class="mb-4 md:mb-0">
        <a href="/#home" class="text-xl font-bold text-text-primary font-heading">Bram Steensma </a>
        <p class="text-text-secondary dark:text-text-muted mt-1">Data Analyst. IT Support Professional. Problem Solver.</p>
        <p class="text-text-secondary dark:text-text-muted mt-2">IT Support Professional breaking into the Data Analysis field.</p>
        <p class="text-text-secondary dark:text-text-muted mt-1">
          <i class="fas fa-map-marker-alt mr-2"></i>Riverton, Nova Scotia, Canada
        </p>
        <a href="mailto:bram.steensma89@gmail.com" class="text-text-secondary dark:text-text-muted text-primary dark:text-primary-light mt-1 inline-block">
          <i class="fas fa-envelope mr-2"></i>bram.steensma89@gmail.com
        </a>
        
        <div class="flex space-x-8 mt-6 items-center" data-animation="social">
          
          <a href="https://www.linkedin.com/in/steensmab/" target="_blank" rel="noopener noreferrer" class="text-text-secondary dark:text-text-muted text-third dark:text-third-light transition-transform duration-300 hover:scale-125">
            
            <i class="fab fa-linkedin-in text-3xl text-text-primary dark:text-text-primary"></i>
            
          </a>
          
          <a href="https://github.com/BramSteensma" target="_blank" rel="noopener noreferrer" class="text-text-secondary dark:text-text-muted text-third dark:text-third-light transition-transform duration-300 hover:scale-125">
            
            <i class="fab fa-github text-3xl text-text-primary dark:text-text-primary"></i>
            
          </a>
          
          
        </div>
      </div>
      <div class="flex flex-col items-end">
        <div class="flex flex-wrap gap-2 justify-end">
          
        </div>
      </div>
    </div>

    <div class="mt-8 pt-8 border-t border-border-primary text-center text-text-secondary dark:text-text-muted text-sm">
      <p>Â© 2026 | Bram Steensma (Powered by Felipe Cordero&#39;s CareerCanvas theme)</p>
    </div>
  </div>
</footer>




    
    
    
    
    
    

<div id="pexels-config" data-queries="[&#34;long span bridges&#34;,&#34;skyscrapers&#34;,&#34;sky and clouds&#34;,&#34;galactic core&#34;]" data-pexels-api-key="" data-formspree-endpoint="https://formspree.io/f/mnjbjlbl" style="display: none;"></div>
<script>
  (function() {
    var el = document.getElementById('pexels-config');
    if (el) {
      window.PEXELS_API_KEY = el.getAttribute('data-pexels-api-key') || '';
      window.FORMSPREE_ENDPOINT = el.getAttribute('data-formspree-endpoint') || '';
      try { window.PEXELS_QUERIES = JSON.parse(el.getAttribute('data-queries')); } catch (e) { window.PEXELS_QUERIES = []; }
    } else {
      window.PEXELS_API_KEY = window.FORMSPREE_ENDPOINT = '';
      window.PEXELS_QUERIES = [];
    }
  })();
</script>

    

<script>
  
  window.HUGO_COLOR_PALETTES = [
    
    {
      name: "midnight",
      main_color: "#0F172A",
      second_color: "#8B5CF6",
      third_color: "#06B6D4"
    }
    
  ];
  
  
  if (window.HUGO_COLOR_PALETTES && window.HUGO_COLOR_PALETTES.length > 0) {
    console.log('ðŸŽ¨ Using color palettes from Hugo config:', window.HUGO_COLOR_PALETTES.length, 'palettes');
  }
</script>

    <script src="/js/scripts.js"></script>
    <script src="/js/dynamic-colors.js"></script>
    <script src="/js/gsap-animations.js"></script>
    <script src="/js/pexels-background.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/fslightbox/index.js"></script>

    
    <script>
        
        if (localStorage.getItem('darkMode') !== 'false') {
            document.documentElement.classList.add('dark');
        } else {
            document.documentElement.classList.remove('dark');
        }

        
        window.addEventListener('load', function() {
            document.body.style.visibility = 'visible';
        });
    </script>
</body>
</html>
